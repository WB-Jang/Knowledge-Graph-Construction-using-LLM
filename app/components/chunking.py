"""
Text chunking utilities for document processing
"""
import re
from typing import List, Dict, Optional
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter


def pdf_to_text(path: str, clean_pattern: Optional[str] = None) -> str:
    """
    Extract text from PDF file

    Args:
        path: Path to PDF file
        clean_pattern: Optional regex pattern to remove unwanted text

    Returns:
        Extracted text
    """
    loader = PyPDFLoader(path)
    pages = loader.load()
    
    if clean_pattern:
        text = "\n".join([re.sub(clean_pattern, "", p.page_content).strip() for p in pages])
    else:
        text = "\n".join([p.page_content.strip() for p in pages])
    
    return text


def chunk_text(
    text: str,
    chunk_size: int = 1000,
    chunk_overlap: int = 200,
    separators: Optional[List[str]] = None,
) -> List[str]:
    """
    Split text into chunks using recursive character text splitter

    Args:
        text: Input text
        chunk_size: Maximum chunk size
        chunk_overlap: Overlap between chunks
        separators: Optional list of separators

    Returns:
        List of text chunks
    """
    if separators is None:
        separators = ["\n\n", "\n", " ", ""]

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=separators,
        length_function=len,
    )

    chunks = splitter.split_text(text)
    return chunks


# 법령의 메타 데이터도 조문 안으로 들어가도록 설정하자
def _pdf_to_text(path: str) -> str:
    """Legacy function for Korean law document processing"""
    pdf_file = path
    loader = PyPDFLoader(pdf_file)
    pages = loader.load()
    text_for_delete = r"법제처\s+\d+\s+국가법령정보센터\n개인정보 보호법"
    law_text = "\n".join([re.sub(text_for_delete, "", p.page_content).strip() for p in pages])
    
    return law_text


def _parse_law(law_text: str) -> List[str]:
    """
    Parse Korean law document into articles
    
    Args:
        law_text: Korean law document text
        
    Returns:
        List of articles
    """
    # 서문 분리
    # '^'로 시작하여 '제1장' 또는 '제1조' 직전까지의 모든 텍스트를 탐색 
    preamble_pattern = r'^(.*?)(?=제1장|제1조)'
    preamble = re.search(preamble_pattern, law_text, re.DOTALL)
    if preamble:
        preamble = preamble.group(1).strip()
    
    # 장 분리 
    # '제X장' 형식의 제목과 그 뒤에 오는 모든 조항을 하나의 그룹화 
    chapter_pattern = r'(제\d+장\s+.+?)\n((?:제\d+조(?:의\d+)?(?:\(\w+\))?.*?)(?=제\d+장|부칙|$))'
    chapters = re.findall(chapter_pattern, law_text, re.DOTALL)
    
    # 부칙 분리
    # '부칙'으로 시작하는 모든 텍스트를 탐색 
    appendix_pattern = r'(부칙.*)'
    appendix = re.search(appendix_pattern, law_text, re.DOTALL)
    if appendix:
        appendix = appendix.group(1)
    
    # 파싱 결과를 저장할 딕셔너리 초기화
    parsed_law = {'서문': preamble, '장': {}, '부칙': appendix}
    
    # 각 장 내에서 조 분리
    for chapter_title, chapter_content in chapters:
        # 조 분리 패턴
        # 1. '제X조'로 시작 ('제X조의Y' 형식도 가능)
        # 2. 조 번호 뒤에 반드시 '(항목명)' 형식의 제목이 와야 함 
        # 3. 다음 조가 시작되기 전까지 또는 문서의 끝까지의 모든 내용을 포함
        article_pattern = r'(제\d+조(?:의\d+)?\s*\([^)]+\).*?)(?=제\d+조(?:의\d+)?\s*\([^)]+\)|$)'
        
        # 정규표현식을 이용해 모든 조항을 탐색 
        articles = re.findall(article_pattern, chapter_content, re.DOTALL)
        
        # 각 조항의 앞뒤 공백을 제거하고 결과 딕셔너리에 저장
        parsed_law['장'][chapter_title.strip()] = [article.strip() for article in articles]

    law_list = []

    for law in parsed_law["장"].keys():
        for article in parsed_law["장"][law]:
            law_list.append(article)
    
    return law_list 
